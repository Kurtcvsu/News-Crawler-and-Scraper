=== AI ===
Title: Parents call for New York governor to sign landmark AI safety bill
Link: https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill
Published: 2025-12-12T17:16:09-05:00

AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI Policy Close Policy Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Policy Parents call for New York governor to sign landmark AI safety bill They called it “minimalist guardrails” that should set a standard. They called it “minimalist guardrails” that should set a standard. by Hayden Field Close Hayden Field Senior AI Reporter Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Hayden Field Dec 12, 2025, 10:16 PM UTC Link Share Image: Cath Virginia / The Verge, Getty Images Hayden Field Close Hayden Field Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Hayden Field is The Verge’s senior AI reporter. An AI beat reporter for more than five years, her work has also appeared in CNBC, MIT Technology Review, Wired UK, and other outlets. A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models — like Meta, OpenAI, Deepseek, and Google — to create safety plans and follow transparency rules about reporting safety incidents. The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California’s SB 53 after large AI companies weighed in on it. Many AI companies, unsurprisingly, are squarely against the legislation. The AI Alliance, which counts Meta, IBM, Intel, Oracle, Snowflake, Uber, AMD, Databricks, and Hugging Face among its members, sent a letter in June to New York lawmakers detailing their “deep concern” about the RAISE Act, calling it “unworkable.” And Leading the Future, the pro-AI super PAC backed by Perplexity AI, Andreessen Horowitz (a16z), OpenAI president Greg Brockman, and Palantir co-founder Joe Lonsdale, has been targeting New York State Assemblymember Alex Bores, who co-sponsored the RAISE Act, with recent ads. Two organizations, ParentsTogether Action and the Tech Oversight Project, put together Friday’s letter to Hochul , which states that some of the signees had “lost children to the harms of AI chatbots and social media.” The signatories called the RAISE Act as it stands now “minimalist guardrails” that should be made law. They also highlighted that the bill, as passed by the New York State Legislature, “does not regulate all AI developers – only the very largest companies, the ones spending hundreds of millions of dollars a year.” They would be required to disclose large-scale safety incidents to the attorney general and publish safety plans. The developers would also be prohibited from releasing a frontier model “if doing so would create an unreasonable risk of critical harm,” which is defined as the death or serious injury of 100 people or more, or $1 billion or more in damages to rights in money or property stemming from the creation of a chemical, biological, radiological, or nuclear weapon; or an AI model that “acts with no meaningful human intervention” and “would, if committed by a human,” fall under certain crimes. “Big Tech’s deep-pocketed opposition to these basic protections looks familiar because we have seen this pattern of avoidance and evasion before,” the letter states. “Widespread damage to young people — including to their mental health, emotional stability, and ability to function in school — has been widely documented ever since the biggest technology companies decided to push algorithmic social media platforms without transparency, oversight, or responsibility.” Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Hayden Field Close Hayden Field Senior AI Reporter Posts from this author will be added to your daily email digest and your homepage feed. Follow Follow See All by Hayden Field AI Close AI Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All AI Policy Close Policy Posts from this topic will be added to your daily email digest and your homepage feed. Follow Follow See All Policy Most Popular Most Popular Does the Trump phone exist yet? iOS 26.2 is here with Liquid Glass, AirDrop, and Apple Music updates Google is building an experimental new browser and a new kind of web app ChatGPT’s ‘adult mode’ is expected to debut in Q1 2026 The TCL QM9K is an excellent flagship TV, but I’m not sure who it’s for The Verge Daily A free daily digest of the news that matters most. Email (required) Sign Up By submitting your email, you agree to our Terms and Privacy Notice . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Advertiser Content From This is the title for the native ad

================================================================================

=== AI ===
Title: AI in 2026: Experimental AI concludes as autonomous systems rise
Link: https://www.artificialintelligence-news.com/news/ai-in-2026-experimental-ai-concludes-autonomous-systems-rise/
Published: Fri, 12 Dec 2025 16:59:18 +0000

Skip to content AI News is part of the TechForge Publications series Explore All Developer IoT News MarketingTech CloudTech Telecoms TechHQ TechWire Asia Explore All Developer IoT News MarketingTech CloudTech Telecoms TechHQ TechWire Asia TechForge News Categories AI and Us Environment & Sustainability Human-AI Relationships Open-Source & Democratised AI Trust, Bias & Fairness World of Work AI in Action Creative Industries Cybersecurity AI Education AI Entertainment & Media Finance AI Government & Public Sector AI Healthcare & Wellness AI Legal Industry AI Manufacturing & Engineering AI Marketing AI Utilities Workforce & HR AI Retail & Logistics AI Service Industry AI How It Works Computer Vision Data Engineering & MLOps Infrastructure & Hardware Multimodal AI Natural Language Processing (NLP) Reinforcement Learning Inside AI AI Business Strategy AI Hardware & Chips AI Market Trends AI Mergers & Acquisitions AI Startups & Funding Founders & Visionaries Governance, Regulation & Policy Features Deep Dives Interviews Opinion Special Reports & Series Sponsored Content TechEx Events All Categories Events Resources All Resources On Demand Webinars Exclusive Videos More About AI News Advertise Contact Us News Categories AI and Us Environment & Sustainability Human-AI Relationships Open-Source & Democratised AI Trust, Bias & Fairness World of Work AI in Action Creative Industries Cybersecurity AI Education AI Entertainment & Media Finance AI Government & Public Sector AI Healthcare & Wellness AI Legal Industry AI Manufacturing & Engineering AI Marketing AI Utilities Workforce & HR AI Retail & Logistics AI Service Industry AI How It Works Computer Vision Data Engineering & MLOps Infrastructure & Hardware Multimodal AI Natural Language Processing (NLP) Reinforcement Learning Inside AI AI Business Strategy AI Hardware & Chips AI Market Trends AI Mergers & Acquisitions AI Startups & Funding Founders & Visionaries Governance, Regulation & Policy Features Deep Dives Interviews Opinion Special Reports & Series Sponsored Content TechEx Events All Categories Events Resources All Resources On Demand Webinars Exclusive Videos More About AI News Advertise Contact Us Search Subscribe Subscribe News Categories AI and Us Environment & Sustainability Human-AI Relationships Open-Source & Democratised AI Trust, Bias & Fairness World of Work AI in Action Creative Industries Cybersecurity AI Education AI Entertainment & Media Finance AI Government & Public Sector AI Healthcare & Wellness AI Legal Industry AI Manufacturing & Engineering AI Marketing AI Utilities Workforce & HR AI Retail & Logistics AI Service Industry AI How It Works Computer Vision Data Engineering & MLOps Infrastructure & Hardware Multimodal AI Natural Language Processing (NLP) Reinforcement Learning Inside AI AI Business Strategy AI Hardware & Chips AI Market Trends AI Mergers & Acquisitions AI Startups & Funding Founders & Visionaries Governance, Regulation & Policy Features Deep Dives Interviews Opinion Special Reports & Series Sponsored Content TechEx Events All Categories Events Resources All Resources On Demand Webinars Exclusive Videos More About AI News Advertise Contact Us Hamburger Toggle Menu Features AI in 2026: Experimental AI concludes as autonomous systems rise Ryan Daws December 12, 2025 Share this story: Tags: agents ai enterprise governance sovereignty strategy work Categories: AI and Us AI Business Strategy Features Governance, Regulation & Policy Human-AI Relationships Inside AI Interviews Open-Source & Democratised AI Opinion Trust, Bias & Fairness World of Work Generative AI’s experimental phase is concluding, making way for truly autonomous systems in 2026 that act rather than merely summarise. 2026 will lose the focus on model parameters and be about agency, energy efficiency, and the ability to navigate complex industrial environments. The next twelve months represent a departure from chatbots toward autonomous systems executing workflows with minimal oversight; forcing organisations to rethink infrastructure, governance, and talent management. Autonomous AI systems take the wheel Hanen Garcia, Chief Architect for Telecommunications at Red Hat , argues that while 2025 was defined by experimentation, the coming year marks a “decisive pivot towards agentic AI, autonomous software entities capable of reasoning, planning, and executing complex workflows without constant human intervention.” Telecoms and heavy industry are the proving grounds. Garcia points to a trajectory toward autonomous network operations (ANO), moving beyond simple automation to self-configuring and self-healing systems. The business goal is to reverse commoditisation by “prioritising intelligence over pure infrastructure” and reduce operating expenditures. Technologically, service providers are deploying multiagent systems (MAS). Rather than relying on a single model, these allow distinct agents to collaborate on multi-step tasks, handling complex interactions autonomously. However, increased autonomy introduces new threats. Emmet King, Founding Partner of J12 Ventures , warns that “as AI agents gain the ability to autonomously execute tasks, hidden instructions embedded in images and workflows become potential attack vectors.” Security priorities must therefore shift from endpoint protection to “governing and auditing autonomous AI actions.” As organisations scale these autonomous AI workloads, they hit a physical wall: power. King argues energy availability, rather than model access, will determine which startups scale. “Compute scarcity is now a function of grid capacity,” King states, suggesting energy policy will become the de facto AI policy in Europe. KPIs must adapt. Sergio Gago, CTO at Cloudera , predicts enterprises will prioritise energy efficiency as a primary metric. “The new competitive edge won’t come from the largest models, but from the most intelligent, efficient use of resources.” Horizontal copilots lacking domain expertise or proprietary data will fail ROI tests as buyers measure real productivity. The “clearest enterprise ROI” will emerge from manufacturing , logistics, and advanced engineering—sectors where AI integrates into high-value workflows rather than consumer-facing interfaces. AI ends the static app in 2026 Software consumption is changing too. Chris Royles, Field CTO for EMEA at Cloudera , suggests the traditional concept of an “app” is becoming fluid. “In 2026, AI will start to radically change the way we think about apps, how they function and how they’re built.” Users will soon request temporary modules generated by code and a prompt, effectively replacing dedicated applications. “Once that function has served its purpose, it closes,” Royles explains, noting these “disposable” apps can be built and rebuilt in seconds. Rigorous governance is required here; organisations need visibility into the reasoning processes used to create these modules to ensure errors are corrected safely. Data storage faces a similar reckoning, especially as AI becomes more autonomous. Wim Stoop, Director of Product Marketing at Cloudera , believes the era of “digital hoarding” is ending as storage capacity hits its limit. “AI-generated data will become disposable, created and refreshed on demand rather than stored indefinitely,” Stoop predicts. Verified, human-generated data will rise in value while synthetic content is discarded. Specialist AI governance agents will pick up the slack. These “digital colleagues” will continuously monitor and secure data, allowing humans to “govern the governance” rather than enforcing individual rules. For example, a security agent could automatically adjust access permissions as new data enters the environment without human intervention. Sovereignty and the human element Sovereignty remains a pressing concern for European IT. Red Hat’s survey data indicates 92 percent of IT and AI leaders in EMEA view enterprise open-source software as vital for achieving sovereignty. Providers will leverage existing data centre footprints to offer sovereign AI solutions, ensuring data remains within specific jurisdictions to meet compliance demands. Emmet King, Founding Partner of J12 Ventures, adds that competitive advantage is moving from owning models to “controlling training pipelines and energy supply,” with open-source advancements allowing more actors to run frontier-scale workloads. Workforce integration is becoming personal. Nick Blasi, Co-Founder of Personos , argues tools ignoring human nuance – tone, temperament, and personality – will soon feel obsolete. By 2026, Blasi predicts “half of workplace conflict will be flagged by AI before managers know it exists.” These systems will focus on “communication, influence, trust, motivation, and conflict resolution,” Blasi suggests, adding that personality science will become the “operating system” for the next generation of autonomous AI, offering grounded understanding of human individuality rather than generic recommendations. The era of the “thin wrapper” is over. Buyers are now measuring real productivity, exposing tools built on hype rather than proprietary data. For the enterprise, competitive advantage will no longer come from renting access to a model, but from controlling the training pipelines and energy supply that power it. See also: BBVA embeds AI into banking workflows using ChatGPT Enterprise Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information. AI News is powered by TechForge Media . Explore other upcoming enterprise technology events and webinars here . About the Author Ryan Daws Senior Editor Ryan Daws is a senior editor at TechForge Media with over a decade of experience in weaving narratives and dissecting complex topics. His articles and interviews with industry leaders have earned him recognition as a key tech influencer from numerous organisations. Under his leadership, publications have been praised by analyst firms for their excellence and performance. Connect with him on X, Mastodon , Bluesky , Threads , and/or LinkedIn . Related BBVA embeds AI into

================================================================================

